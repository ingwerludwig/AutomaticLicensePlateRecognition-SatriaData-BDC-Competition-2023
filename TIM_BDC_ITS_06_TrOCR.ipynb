{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "uvVWkfiiay0r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlwCc63yoarj"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install torch torchvision torchaudio\n",
        "%pip install -q datasets jiwer\n",
        "%pip install install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "id": "0ifOmOFaZLWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate>=0.30"
      ],
      "metadata": {
        "id": "5HrOtRKNa-ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "-OdyLRdfbABk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VegIVD6Zoh-N"
      },
      "outputs": [],
      "source": [
        "import os, sys, itertools\n",
        "os.environ['TOKENIZERS_PARALLELISM']='false'\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "import transformers\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import VisionEncoderDecoderModel, TrOCRProcessor, default_data_collator\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import cv2\n",
        "import imutils as im\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import evaluate\n",
        "import json\n",
        "import zipfile\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf augmented_images\n",
        "%rm -rf DataTrain_augmented.csv\n",
        "# %rm -rf DataTrainOriginal\n",
        "# %rm -rf DataTestOriginal"
      ],
      "metadata": {
        "id": "GEM_wwdcxfy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Augmentation"
      ],
      "metadata": {
        "id": "Q08NxkG8I4K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import os\n",
        "# import cv2\n",
        "# import imgaug as ia\n",
        "# from imgaug import augmenters as iaa\n",
        "\n",
        "# # Define the augmentation sequence\n",
        "# augmentation_seq = iaa.Sequential([\n",
        "#     iaa.MultiplyHueAndSaturation((0.8, 1.2)),  # Multiply the hue and saturation by a random value between 0.8 and 1.2\n",
        "#     iaa.GaussianBlur(sigma=(0, 1.0)),  # Apply Gaussian blur with a sigma between 0 and 1.0\n",
        "# ])\n",
        "\n",
        "# # Read the CSV file\n",
        "# csv_file = '/content/DataTrain.csv'  # Replace with the path to your CSV file\n",
        "# df = pd.read_csv(csv_file)\n",
        "\n",
        "# # Define the output directory for augmented images\n",
        "# output_dir = 'augmented_images'  # Replace with the desired output directory\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# # Perform image augmentation and save the augmented images\n",
        "# for index, row in df.iterrows():\n",
        "#     image_name = row['NameofFile']\n",
        "#     license_plate = row['Vehicleregistrationplate']\n",
        "\n",
        "#     # Load the image\n",
        "#     image_path = os.path.join('/content/DataTrainOriginal', image_name)  # Replace 'DataTrainOriginal' with the directory where the original images are stored\n",
        "#     image = cv2.imread(image_path)\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#     # Apply augmentation\n",
        "#     augmented_images = augmentation_seq(images=[image] * 2)  # Generate 3 augmented images for each original image\n",
        "\n",
        "#     # Save the augmented images\n",
        "#     for i, augmented_image in enumerate(augmented_images):\n",
        "#         augmented_image_name = f'DataTrain{800 + index * 2 + i + 1}.png'  # Generate new file names based on the augmentation order\n",
        "#         augmented_image_path = os.path.join(output_dir, augmented_image_name)\n",
        "#         augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
        "#         cv2.imwrite(augmented_image_path, augmented_image)\n",
        "\n",
        "#         # Append the new file name and corresponding license plate number to the DataFrame\n",
        "#         df = df.append({'NameofFile': augmented_image_name, 'Vehicleregistrationplate': license_plate}, ignore_index=True)\n",
        "\n",
        "# # Save the updated CSV file\n",
        "# augmented_csv_file = 'DataTrain_augmented.csv'  # Replace with the desired path and file name for the updated CSV file\n",
        "# df.to_csv(augmented_csv_file, index=False)\n"
      ],
      "metadata": {
        "id": "jpUsGRM0xSyr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "56e9871a-f7c0-4bea-de48-869b70b08b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# source_folder = '/content/augmented_images'  # Replace with the path to the source folder\n",
        "# destination_folder = '/content/DataTrainOriginal'  # Replace with the path to the destination folder\n",
        "\n",
        "# # List all files in the source folder\n",
        "# files = os.listdir(source_folder)\n",
        "\n",
        "# # Move each file to the destination folder\n",
        "# for file_name in files:\n",
        "#     source_path = os.path.join(source_folder, file_name)\n",
        "#     destination_path = os.path.join(destination_folder, file_name)\n",
        "#     shutil.move(source_path, destination_path)\n",
        "\n",
        "# print(\"Files moved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqMLeH5xG3Kr",
        "outputId": "3deda894-df70-4231-f81c-7463d5b6ae18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files moved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %rm -rf augmented_images"
      ],
      "metadata": {
        "id": "6uQSD_w7N5ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %rm -rf DataTrain.csv"
      ],
      "metadata": {
        "id": "40d1-Qj4OCiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# current_file_path = '/content/DataTrain_augmented.csv'  # Replace with the path to the current file\n",
        "# new_file_name = 'DataTrain.csv'  # Replace with the new file name\n",
        "\n",
        "# # Rename the file\n",
        "# new_file_path = os.path.join(os.path.dirname(current_file_path), new_file_name)\n",
        "# os.rename(current_file_path, new_file_path)\n",
        "\n",
        "# print(\"File renamed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMKrLZDmOOD_",
        "outputId": "0340a217-ab24-497b-9007-e5e2bfc1f1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File renamed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Util For Removing Folder"
      ],
      "metadata": {
        "id": "UMpQdgoUBCq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %rm -rf PreprocessedTestImages\n",
        "# %rm -rf WarpedTestImages\n",
        "# %rm -rf PreprocessedTrainImages\n",
        "# %rm -rf WarpedTrainImages"
      ],
      "metadata": {
        "id": "StdwV666BGTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Init"
      ],
      "metadata": {
        "id": "I23SU1sk_Hlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to sort the 4 edges of the plate for consistency"
      ],
      "metadata": {
        "id": "gfKNkIhD_d80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to sort the 4 edges of the plate for consistency\n",
        "def arrange_point(points):\n",
        "  # The coordinates will be sorted in the order left-top-right, bottom-right and bottom-left\n",
        "  coord_rect = np.zeros((4, 2),dtype=\"float32\")\n",
        "\n",
        "  # The top-left dot will have the smallest number and the bottom-right dot will have the largest amount\n",
        "  s = points.sum(axis = 1)\n",
        "  coord_rect[0] = points[np.argmin(s)]\n",
        "  coord_rect[2] = points[np.argmax(s)]\n",
        "\n",
        "  # The top-right point will have the smallest reduction result and the bottom-left point will have the largest reduction result\n",
        "  difference = np.diff(points, axis = 1)\n",
        "  coord_rect[1] = points[np.argmin(difference)]\n",
        "  coord_rect[3] = points[np.argmax(difference)]\n",
        "  return coord_rect"
      ],
      "metadata": {
        "id": "ru5OVZKJ_eY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to Cropping Selected Image"
      ],
      "metadata": {
        "id": "MIUbpXdH_e5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for image transformation by taking pictures in the 4-point area\n",
        "def image_transformation(image, points):\n",
        "\n",
        "\t(tl, tr, br, bl) = points\n",
        "\n",
        "  # Calculates the maximum image width\n",
        "\twidth_1 = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "\twidth_2 = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "\tmax_width = max(int(width_1), int(width_2))\n",
        "\n",
        "\t# Calculates the maximum image height\n",
        "\theight_1 = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "\theight_2 = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "\tmax_height = max(int(height_1), int(height_2))\n",
        "\n",
        "  # Transform the image by taking 4 points to get a top view of the desired image area\n",
        "\tdst = np.array([\n",
        "\t\t[0, 0],\n",
        "\t\t[max_width - 1, 0],\n",
        "\t\t[max_width - 1, max_height - 1],\n",
        "\t\t[0, max_height - 1]\n",
        "  ], dtype = \"float32\")\n",
        "\n",
        "\t# Calculating the Transformation Matrix\n",
        "\tMatrix = cv2.getPerspectiveTransform(points, dst)\n",
        "\tresult = cv2.warpPerspective(image, Matrix, (max_width, max_height))\n",
        "\treturn result"
      ],
      "metadata": {
        "id": "RFxu27mK_pwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calculate Maximum Angle"
      ],
      "metadata": {
        "id": "D39HNr5v_vMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the maximum angle of the horizontal line from the edge of the detected plate\n",
        "def count_angle(points) :\n",
        "  upper_left, upper_right, lower_right, lower_left = points\n",
        "\n",
        "  # Calculates the width and height of a pair of sides\n",
        "  height_1 = (upper_right[1]-upper_left[1])\n",
        "  width_1 = (upper_right[0]-upper_left[0])\n",
        "  height_2 = (lower_right[1]-lower_left[1])\n",
        "  width_2 = (lower_right[0]-lower_left[0])\n",
        "\n",
        "  # Finds the maximum angle relative to the horizontal line\n",
        "  # Positive angle clockwise from the positive x-axis\n",
        "  degree_1 = math.atan2(height_1,width_1)\n",
        "  degree_2 = math.atan2(height_2,width_2)\n",
        "\n",
        "  if degree_1>=0 and degree_2>=0 :\n",
        "    degree = max(degree_1,degree_2)\n",
        "  elif degree_1<0 and degree_2>=0 :\n",
        "    degree = degree_1\n",
        "  elif degree_1>=0 and degree_2<0 :\n",
        "    degree = degree_2\n",
        "  elif degree_1<0 and degree_2<0 :\n",
        "    degree = -1*(max(abs(degree_1),abs(degree_2)))\n",
        "  else :\n",
        "    degree = 0\n",
        "\n",
        "  # mengubah dari unit radian ke derajat\n",
        "  phi = math.pi\n",
        "  degree_unit = (degree/(2*phi)*360)\n",
        "\n",
        "  #return sudut dalam satuan derajat\n",
        "  return degree_unit"
      ],
      "metadata": {
        "id": "wDZ0hv7I_vfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to Locate License Plate"
      ],
      "metadata": {
        "id": "OS-m8qQmAEQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for localization of vehicle plate candidates\n",
        "def select_license_plate_area(gray, keep=3):\n",
        "\n",
        "  # Performs a blackhat morphological operation to bring out dark areas on a bright background\n",
        "  rectKern = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
        "  blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKern)\n",
        "\n",
        "  # Looking for bright areas in the image with close morphological operation\n",
        "  squareKern = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "  light = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, squareKern)\n",
        "  # light = cv2.cvtColor(light, cv2.COLOR_BGR2GRAY)\n",
        "  light = cv2.threshold(light, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  # Sharpen the gradient edge features with the scharr method on the x axis\n",
        "  # Then returns the range of pixel values ​​to [0.255]\n",
        "  gradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F,\n",
        "  dx=1, dy=0, ksize=-1)\n",
        "  gradX = np.absolute(gradX)\n",
        "  (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
        "  gradX = 255 * ((gradX - minVal) / (maxVal - minVal))\n",
        "  gradX = gradX.astype(\"uint8\")\n",
        "\n",
        "  # Perform a gaussian blur on the image then perform a closing morphological operation and then perform tresholding using the otsu method\n",
        "  gradX = cv2.GaussianBlur(gradX, (5, 5), 0)\n",
        "  gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKern)\n",
        "  # gradX = cv2.cvtColor(gradX, cv2.COLOR_BGR2GRAY)\n",
        "  thresh = cv2.threshold(gradX, 0, 255,\n",
        "\t\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  # Perform erode and dilate operations to remove noise outside of significant objects\n",
        "  thresh = cv2.erode(thresh, None, iterations=3)\n",
        "  thresh = cv2.dilate(thresh, None, iterations=3)\n",
        "\n",
        "  # Masking with the light image from the previous function to focus the image on the bright part (where the plate is located)\n",
        "  # Then perform dilate and erode operations to remove noise in significant objects\n",
        "  thresh = cv2.bitwise_and(thresh, thresh, mask=light)\n",
        "  thresh = cv2.dilate(thresh, None, iterations=5)\n",
        "  thresh = cv2.erode(thresh, None, iterations=5)\n",
        "\n",
        "  # Search for closed contours of the image\n",
        "  cnts,hir = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts=sorted(cnts, key = cv2.contourArea, reverse = True)\n",
        "\n",
        "  # Template for masking\n",
        "  mask = np.ones(image.shape[:2], dtype=\"uint8\") * 255\n",
        "\n",
        "  if len(cnts) >= 4 :\n",
        "    cv2.drawContours(mask, cnts[4:], -1, 0, -1)\n",
        "  thresh = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
        "\n",
        "  # Masking for contours that have a smaller size compared to the main object contour\n",
        "  for c in cnts :\n",
        "    if cv2.arcLength(c,True) < 0.25*cv2.arcLength(cnts[0],True) :\n",
        "      cv2.drawContours(mask, [c], -1, 0, -1)\n",
        "  thresh = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
        "\n",
        "  cnts,hir = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts=sorted(cnts, key = cv2.contourArea, reverse = True)\n",
        "\n",
        "  # Make a boundary box of all objects that are estimated as vehicle plates in binary images\n",
        "  points = cv2.findNonZero(thresh)\n",
        "  xandy, dimension, degree = cv2.minAreaRect(points)\n",
        "  dimension = list(dimension)\n",
        "  dimension[0] = 1*dimension[0]+10\n",
        "  dimension[1] = 1*dimension[1]+10\n",
        "  rect = []\n",
        "  rect.append(xandy)\n",
        "  rect.append(dimension)\n",
        "  rect.append(degree)\n",
        "  rect = tuple(rect)\n",
        "\n",
        "  # Variable to store the coordinates of 4 corner points from the bounding box prediction for vehicle plates\n",
        "  box = cv2.boxPoints(rect)\n",
        "  box = np.int0(box)\n",
        "\n",
        "  # return coordinates and localized images\n",
        "  return box,thresh"
      ],
      "metadata": {
        "id": "wW1TkHQmAC3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm For Localization"
      ],
      "metadata": {
        "id": "MZ8PbYVHANWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def closed_contour_method(image) :\n",
        "  gray = image\n",
        "\n",
        "  # Removing Noise using Gaussian Blur\n",
        "  denoised_img = cv2.GaussianBlur(gray,(5,5),0)\n",
        "\n",
        "  # Searching for edges of image using Canny\n",
        "  lower, upper = 50, 150\n",
        "  edged = cv2.Canny(denoised_img, lower, upper)\n",
        "\n",
        "  # Looking for closed contours from the image then sorted from the largest\n",
        "  contours,hir = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  contours=sorted(contours, key = cv2.contourArea, reverse = True)[:10]\n",
        "  NumberPlateCnt = np.zeros((4,2))\n",
        "\n",
        "  # Look for contours that have potential as plate objects\n",
        "  count = 0\n",
        "  for contour in contours:\n",
        "        peri = cv2.arcLength(contour, True)\n",
        "        # Approximate potential contour length\n",
        "        epsilon = 0.01 * peri\n",
        "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "        # Selecting a contour with 4 points (quadrilateral)\n",
        "        if len(approx) == 4  :\n",
        "            NumberPlateCnt = approx\n",
        "            NumberPlateCnt = NumberPlateCnt.reshape(4,2)\n",
        "            count += 1\n",
        "            break\n",
        "  return NumberPlateCnt"
      ],
      "metadata": {
        "id": "qyvZUNf4_bUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perfom Plate Localization"
      ],
      "metadata": {
        "id": "WNkuvw6E_NAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_plate_localization(image):\n",
        "  counter = 0\n",
        "\n",
        "  # Menggunakan cara closed Contour\n",
        "  NumberPlateCnt = closed_contour_method(image)\n",
        "\n",
        "  # Jika cara closed contour tidak dapat mendeteksi\n",
        "  if NumberPlateCnt.all() == 0:\n",
        "      # Menggunakan metode morphological operation\n",
        "      imagen = cv2.bitwise_not(image)\n",
        "      NumberPlateCnt, thresh = select_license_plate_area(imagen)\n",
        "\n",
        "  # Proses Transformasi gambar\n",
        "  ordered_points = arrange_point(NumberPlateCnt)\n",
        "  warped_images = image_transformation(image, ordered_points)\n",
        "\n",
        "  # Menghitung sudut maksimum dari gambar\n",
        "  degree = count_angle(ordered_points)\n",
        "  epsilon = 1\n",
        "\n",
        "  # Error Correction untuk gambar miring dengan sudut kecil\n",
        "  if abs(degree) < 5:\n",
        "      rotated = im.rotate_bound(warped_images, 2)\n",
        "  else:\n",
        "      # Error Correction untuk gambar yang miring\n",
        "      if degree <= 0:  # Jika sudut negatif (sisi kiri lebih rendah dari sisi kanan)\n",
        "          rotated = im.rotate_bound(warped_images, -1 * (0.1 * degree) + epsilon)\n",
        "      else:  # Jika sudut positif (sisi kanan lebih rendah dari sisi kiri)\n",
        "          rotated = im.rotate_bound(warped_images, 0.05 * degree + epsilon)\n",
        "  contour_drown = cv2.drawContours(image, [NumberPlateCnt], -1, (255, 0, 0), 2)\n",
        "  return (contour_drown,warped_images)"
      ],
      "metadata": {
        "id": "uXWKctBh_LBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to Image Preprocessing"
      ],
      "metadata": {
        "id": "66ER134zAckq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing function\n",
        "def perform_image_preprocessing(image):\n",
        "    try:\n",
        "        # Check if the image is None or has invalid data\n",
        "        if image is None or len(image.shape) < 3:\n",
        "            raise ValueError(\"Invalid image format.\")\n",
        "\n",
        "        # Convert image to RGB if it is in BGR format\n",
        "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Apply denoising to the image\n",
        "        denoised_image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
        "\n",
        "        # Normalize image to range [0, 1]\n",
        "        denoised_image = denoised_image / 255.0\n",
        "\n",
        "        # Convert image to 8-bit unsigned integer (CV_8U)\n",
        "        denoised_image = (denoised_image * 255).astype(np.uint8)\n",
        "\n",
        "        # Convert image to grayscale\n",
        "        gray = cv2.cvtColor(denoised_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Apply CLAHE to grayscale image\n",
        "        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))\n",
        "        equalized_image = clahe.apply(gray)\n",
        "\n",
        "        return equalized_image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred during image preprocessing: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "wR4WXK9vAeun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Path Definition"
      ],
      "metadata": {
        "id": "gLrZHo3vAjO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %rm -rf DataTest\n",
        "# %rm -rf PreprocessedTestImages\n",
        "# %rm -rf WarpedTestImages\n",
        "\n",
        "# %rm -rf PreprocessedTrainImages\n",
        "# %rm -rf WarpedTrainImages\n",
        "\n",
        "# %rm -rf PreprocessedTestImages.zip\n",
        "# %rm -rf WarpedTestImages.zip\n",
        "\n",
        "# %rm -rf PreprocessedTrainImages.zip\n",
        "# %rm -rf WarpedTrainImages.zip"
      ],
      "metadata": {
        "id": "C_TaGvAQbpig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_csv_file = 'DataTest.csv'\n",
        "test_image_folder_original = 'DataTestOriginal'\n",
        "\n",
        "train_csv_file = 'DataTrain.csv'\n",
        "train_image_folder_original = 'DataTrainOriginal'\n",
        "\n",
        "base_path = '/content/'\n",
        "\n",
        "test_csv_path = os.path.join(base_path, test_csv_file)\n",
        "test_image_folder_path = os.path.join(base_path, test_image_folder_original)\n",
        "train_csv_path = os.path.join(base_path, train_csv_file)\n",
        "train_image_folder_path = os.path.join(base_path, train_image_folder_original)\n",
        "\n",
        "# Load the CSV file and read the image paths\n",
        "df_test = pd.read_csv('DataTest.csv')\n",
        "test_image_paths = df_test['Name of File'].apply(lambda x: os.path.join(test_image_folder_path, x)).values\n",
        "\n",
        "df_train = pd.read_csv('DataTrain.csv')\n",
        "train_image_paths = df_train['NameofFile'].apply(lambda x: os.path.join(train_image_folder_path, x)).values\n",
        "\n",
        "# Preprocess and save the images\n",
        "preprocessed_folder_test = os.path.join(os.getcwd(), 'PreprocessedTestImages')\n",
        "os.makedirs(preprocessed_folder_test, exist_ok=True)\n",
        "\n",
        "# Warped and save the images\n",
        "warped_folder_test = os.path.join(os.getcwd(), 'WarpedTestImages')\n",
        "os.makedirs(warped_folder_test, exist_ok=True)\n",
        "\n",
        "# Preprocess and save the images\n",
        "preprocessed_folder_train = os.path.join(os.getcwd(), 'PreprocessedTrainImages')\n",
        "os.makedirs(preprocessed_folder_train, exist_ok=True)\n",
        "\n",
        "# Warped and save the images\n",
        "warped_folder_train = os.path.join(os.getcwd(), 'WarpedTrainImages')\n",
        "os.makedirs(warped_folder_train, exist_ok=True)\n",
        "\n",
        "\n",
        "preprocessed_images_list_test = []\n",
        "warped_images_list_test = []\n",
        "\n",
        "preprocessed_images_list_train = []\n",
        "warped_images_list_train = []"
      ],
      "metadata": {
        "id": "yx8v7TT4AlWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Image Preprocessing"
      ],
      "metadata": {
        "id": "Vf56eeNDA1ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for image_path in test_image_paths:\n",
        "#     image = cv2.imread(image_path)\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#     plt.rcParams[\"figure.figsize\"] = [12, 8]  # Customize the width and height as desired\n",
        "\n",
        "#     # # Display the original image\n",
        "#     # plt.subplot(2, 2, 1)\n",
        "#     # plt.imshow(image)\n",
        "#     # plt.title('Original Image')\n",
        "\n",
        "#     preprocessed_image = perform_image_preprocessing(image)\n",
        "\n",
        "#     if preprocessed_image is not None:\n",
        "#         preprocessed_image_path = os.path.join(preprocessed_folder_test, os.path.basename(image_path))\n",
        "#         cv2.imwrite(preprocessed_image_path, preprocessed_image)\n",
        "#         preprocessed_images_list_test.append(preprocessed_image_path)\n",
        "\n",
        "#         # Display the preprocessed image\n",
        "#         # plt.subplot(2, 2, 2)\n",
        "#         # plt.imshow(preprocessed_image, cmap='gray')\n",
        "#         # plt.title('Preprocessed Image')\n",
        "#         # plt.show()\n",
        "\n",
        "#         contour_drawn,warped_images = perform_plate_localization(preprocessed_image)\n",
        "#         warped_image_path = os.path.join(warped_folder_test, os.path.basename(image_path))\n",
        "#         cv2.imwrite(warped_image_path, warped_images)\n",
        "#         warped_images_list_test.append(warped_image_path)\n",
        "\n",
        "#         # plt.subplot(2, 2, 3)\n",
        "#         # plt.imshow(contour_drawn, cmap='gray')\n",
        "#         # plt.title('Contoured Image')\n",
        "\n",
        "#         # plt.subplot(2, 2, 4)\n",
        "#         # plt.imshow(warped_images, cmap='gray')\n",
        "#         # plt.title('Warped Image')\n",
        "#         # plt.show()\n",
        "#     else:\n",
        "#         print(f\"Skipping image {image_path} due to preprocessing error.\")\n",
        "\n",
        "# print(\"Preprocessing and saving of images complete.\")"
      ],
      "metadata": {
        "id": "Aygs5qOJA21E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Image Preprocessing"
      ],
      "metadata": {
        "id": "GzPpllNgZJKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for image_path in train_image_paths:\n",
        "#     image = cv2.imread(image_path)\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#     plt.rcParams[\"figure.figsize\"] = [12, 8]  # Customize the width and height as desired\n",
        "\n",
        "#     # # Display the original image\n",
        "#     # plt.subplot(2, 2, 1)\n",
        "#     # plt.imshow(image)\n",
        "#     # plt.title('Original Image')\n",
        "\n",
        "#     preprocessed_image = perform_image_preprocessing(image)\n",
        "\n",
        "#     if preprocessed_image is not None:\n",
        "#         preprocessed_image_path = os.path.join(preprocessed_folder_train, os.path.basename(image_path))\n",
        "#         cv2.imwrite(preprocessed_image_path, preprocessed_image)\n",
        "#         preprocessed_images_list_train.append(preprocessed_image_path)\n",
        "\n",
        "#         # Display the preprocessed image\n",
        "#         # plt.subplot(2, 2, 2)\n",
        "#         # plt.imshow(preprocessed_image, cmap='gray')\n",
        "#         # plt.title('Preprocessed Image')\n",
        "#         # plt.show()\n",
        "\n",
        "#         contour_drawn,warped_images = perform_plate_localization(preprocessed_image)\n",
        "#         warped_image_path = os.path.join(warped_folder_train, os.path.basename(image_path))\n",
        "#         cv2.imwrite(warped_image_path, warped_images)\n",
        "#         warped_images_list_train.append(warped_image_path)\n",
        "\n",
        "#         # plt.subplot(2, 2, 3)\n",
        "#         # plt.imshow(contour_drawn, cmap='gray')\n",
        "#         # plt.title('Contoured Image')\n",
        "\n",
        "#         # plt.subplot(2, 2, 4)\n",
        "#         # plt.imshow(warped_images, cmap='gray')\n",
        "#         # plt.title('Warped Image')\n",
        "#         # plt.show()\n",
        "#     else:\n",
        "#         print(f\"Skipping image {image_path} due to preprocessing error.\")\n",
        "\n",
        "# print(\"Preprocessing and saving of images complete.\")"
      ],
      "metadata": {
        "id": "JCwMJMY9ZLFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Result"
      ],
      "metadata": {
        "id": "rwYpBViUA6nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create a zip file containing the preprocessed images\n",
        "# zip_file_path = os.path.join(os.getcwd(), 'PreprocessedTrainImages.zip')\n",
        "# with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
        "#     for image_path in preprocessed_images_list_train:\n",
        "#         zipf.write(image_path, os.path.basename(image_path))\n",
        "\n",
        "# # Create a zip file containing the preprocessed images\n",
        "# zip_warped_file_path = os.path.join(os.getcwd(), 'WarpedTrainImages.zip')\n",
        "# with zipfile.ZipFile(zip_warped_file_path, 'w') as zipf:\n",
        "#     for image_path in warped_images_list_train:\n",
        "#         zipf.write(image_path, os.path.basename(image_path))\n",
        "\n",
        "# print(\"Preprocessed images zipped.\")"
      ],
      "metadata": {
        "id": "bkzoFHaRA8gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create a zip file containing the preprocessed images\n",
        "# zip_file_path = os.path.join(os.getcwd(), 'PreprocessedTestImages.zip')\n",
        "# with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
        "#     for image_path in preprocessed_images_list_test:\n",
        "#         zipf.write(image_path, os.path.basename(image_path))\n",
        "\n",
        "# # Create a zip file containing the preprocessed images\n",
        "# zip_warped_file_path = os.path.join(os.getcwd(), 'WarpedTestImages.zip')\n",
        "# with zipfile.ZipFile(zip_warped_file_path, 'w') as zipf:\n",
        "#     for image_path in warped_images_list_test:\n",
        "#         zipf.write(image_path, os.path.basename(image_path))\n",
        "\n",
        "# print(\"Preprocessed images zipped.\")"
      ],
      "metadata": {
        "id": "bKzFMib8CW1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir DataTest"
      ],
      "metadata": {
        "id": "Ts2aoMnbGXgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "ZGJlBH5zbDrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_folder = \"/content/drive/MyDrive/satriadata/DataTest\"\n",
        "save_dir = \"/content/drive/MyDrive/satriadata\"\n",
        "drive_folder = \"/content/drive/MyDrive/satriadata\""
      ],
      "metadata": {
        "id": "BYV5gxh9dPxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JlLEvzZpXmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2323ccf-c18f-4297-d93a-5d97f45ac090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 640 entries, 0 to 639\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   text       640 non-null    object\n",
            " 1   file_name  640 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 10.1+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160 entries, 0 to 159\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   text       160 non-null    object\n",
            " 1   file_name  160 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "path = \"DataTrain.csv\"\n",
        "\n",
        "dataset = pd.read_csv(path)\n",
        "\n",
        "dataset.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
        "dataset.rename(columns={\"NameofFile\" : \"file_name\", \"Vehicleregistrationplate\" : \"text\"}, inplace=True)\n",
        "\n",
        "# train/test split\n",
        "train_dataset, test_dataset = train_test_split(dataset, train_size=0.80, random_state=42)\n",
        "\n",
        "train_dataset.reset_index(drop=True, inplace=True)\n",
        "test_dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(train_dataset.info())\n",
        "print(test_dataset.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sV9jgu3EsU2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "2f23aee2-2c1e-4cfe-f482-4ff08e01f44c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         text         file_name\n",
              "0       A7814    DataTrain1.png\n",
              "1     B1074QO    DataTrain2.png\n",
              "2     B1031QO    DataTrain3.png\n",
              "3     B187EDA    DataTrain4.png\n",
              "4     B1089VD    DataTrain5.png\n",
              "..        ...               ...\n",
              "795  B1677EJC  DataTrain796.png\n",
              "796   B1743VO  DataTrain797.png\n",
              "797  AD1416YD  DataTrain798.png\n",
              "798  AB5419TN  DataTrain799.png\n",
              "799  AB6315SE  DataTrain800.png\n",
              "\n",
              "[800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8ad8eb1-9f49-4573-ba97-7930915d5936\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A7814</td>\n",
              "      <td>DataTrain1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B1074QO</td>\n",
              "      <td>DataTrain2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B1031QO</td>\n",
              "      <td>DataTrain3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B187EDA</td>\n",
              "      <td>DataTrain4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B1089VD</td>\n",
              "      <td>DataTrain5.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>B1677EJC</td>\n",
              "      <td>DataTrain796.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>B1743VO</td>\n",
              "      <td>DataTrain797.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>AD1416YD</td>\n",
              "      <td>DataTrain798.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>AB5419TN</td>\n",
              "      <td>DataTrain799.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>AB6315SE</td>\n",
              "      <td>DataTrain800.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8ad8eb1-9f49-4573-ba97-7930915d5936')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8ad8eb1-9f49-4573-ba97-7930915d5936 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8ad8eb1-9f49-4573-ba97-7930915d5936');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFlsAFzSsJGn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "f39505f4-c6dd-4cdf-bd2a-80a33c3a3603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         text         file_name\n",
              "0     B1260UL  DataTrain265.png\n",
              "1     A7692KC  DataTrain616.png\n",
              "2    B1661TKZ  DataTrain330.png\n",
              "3    B1058WYD  DataTrain343.png\n",
              "4    AE9562NJ  DataTrain395.png\n",
              "..        ...               ...\n",
              "635   B1028QO   DataTrain72.png\n",
              "636   A1565DT  DataTrain107.png\n",
              "637  B1925KEP  DataTrain271.png\n",
              "638   B123MBM  DataTrain436.png\n",
              "639  B1136UZU  DataTrain103.png\n",
              "\n",
              "[640 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08a16f1d-2e20-4e34-9da1-e969b2328f12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B1260UL</td>\n",
              "      <td>DataTrain265.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A7692KC</td>\n",
              "      <td>DataTrain616.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B1661TKZ</td>\n",
              "      <td>DataTrain330.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B1058WYD</td>\n",
              "      <td>DataTrain343.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AE9562NJ</td>\n",
              "      <td>DataTrain395.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>B1028QO</td>\n",
              "      <td>DataTrain72.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>A1565DT</td>\n",
              "      <td>DataTrain107.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>637</th>\n",
              "      <td>B1925KEP</td>\n",
              "      <td>DataTrain271.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>B123MBM</td>\n",
              "      <td>DataTrain436.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>639</th>\n",
              "      <td>B1136UZU</td>\n",
              "      <td>DataTrain103.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>640 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08a16f1d-2e20-4e34-9da1-e969b2328f12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08a16f1d-2e20-4e34-9da1-e969b2328f12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08a16f1d-2e20-4e34-9da1-e969b2328f12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yC9NCujf-jDm",
        "outputId": "71671046-5d4d-435a-9faf-6d32fbd83a4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         text         file_name\n",
              "0     A9529ZB  DataTrain697.png\n",
              "1     B1073QO  DataTrain668.png\n",
              "2    AB6677RU   DataTrain64.png\n",
              "3     B1863WW  DataTrain534.png\n",
              "4    B1739TZI   DataTrain67.png\n",
              "..        ...               ...\n",
              "155  B1830PJK  DataTrain590.png\n",
              "156  AB5419TN  DataTrain799.png\n",
              "157  B1038TZC  DataTrain745.png\n",
              "158   B1404GT  DataTrain514.png\n",
              "159  B1253BAC  DataTrain671.png\n",
              "\n",
              "[160 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5c6761d-4341-437d-bf99-c614dc90f5de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A9529ZB</td>\n",
              "      <td>DataTrain697.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B1073QO</td>\n",
              "      <td>DataTrain668.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AB6677RU</td>\n",
              "      <td>DataTrain64.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B1863WW</td>\n",
              "      <td>DataTrain534.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B1739TZI</td>\n",
              "      <td>DataTrain67.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>B1830PJK</td>\n",
              "      <td>DataTrain590.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>AB5419TN</td>\n",
              "      <td>DataTrain799.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>B1038TZC</td>\n",
              "      <td>DataTrain745.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>B1404GT</td>\n",
              "      <td>DataTrain514.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>B1253BAC</td>\n",
              "      <td>DataTrain671.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5c6761d-4341-437d-bf99-c614dc90f5de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5c6761d-4341-437d-bf99-c614dc90f5de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5c6761d-4341-437d-bf99-c614dc90f5de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Solution"
      ],
      "metadata": {
        "id": "UjNUfxUVbGuf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbLctEPgskVt"
      },
      "outputs": [],
      "source": [
        "class License_Plates_OCR_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, df, processor, max_target_length=128):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get file name + text\n",
        "        file_name = self.df['file_name'][idx]\n",
        "        text = self.df['text'][idx]\n",
        "        # prepare image (i.e. resize + normalize)\n",
        "        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
        "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
        "        # add labels (input_ids) by encoding the text\n",
        "        labels = self.processor.tokenizer(text, padding=\"max_length\", max_length=self.max_target_length).input_ids\n",
        "        # important: make sure that PAD tokens are ignored by the loss function\n",
        "        labels = [label if label != self.processor.tokenizer.pad_token_id\n",
        "                  else -100 for label in labels]\n",
        "\n",
        "        encoding = {\"pixel_values\" : pixel_values.squeeze(), \"labels\" : torch.tensor(labels)}\n",
        "        return encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import PreTrained Model TrOCR"
      ],
      "metadata": {
        "id": "jmwtJ251bSZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf trocr-base-printed_license_plates_ocr"
      ],
      "metadata": {
        "id": "xxUhKt5VCpHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBwJgRXitd61"
      },
      "outputs": [],
      "source": [
        "MODEL_CKPT = \"microsoft/trocr-large-str\"\n",
        "MODEL_NAME =  MODEL_CKPT.split(\"/\")[-1] + \"_license_plates_ocr\"\n",
        "NUM_OF_EPOCHS = 8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrOCRProcessor\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-str\")"
      ],
      "metadata": {
        "id": "BiuKtJg6bcct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc233f0e-4405-421f-9286-3b84b3c568b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1aj923dFZL8"
      },
      "outputs": [],
      "source": [
        "model = VisionEncoderDecoderModel.from_pretrained(MODEL_CKPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Train Test Dataset"
      ],
      "metadata": {
        "id": "tz1vkiuEbfSM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSTDwbIftvuz"
      },
      "outputs": [],
      "source": [
        "train_ds = License_Plates_OCR_Dataset(root_dir=\"/content/PreprocessedTrainImages/\",\n",
        "                             df=train_dataset,\n",
        "                             processor=processor)\n",
        "\n",
        "test_ds = License_Plates_OCR_Dataset(root_dir=\"/content/PreprocessedTrainImages/\",\n",
        "                             df=test_dataset,\n",
        "                             processor=processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UfrjuGT-poU",
        "outputId": "254f2fc7-10ae-47d4-e7d5-76b253cb1a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training dataset has 640 samples in it.\n",
            "The testing dataset has 160 samples in it.\n"
          ]
        }
      ],
      "source": [
        "print(f\"The training dataset has {len(train_ds)} samples in it.\")\n",
        "print(f\"The testing dataset has {len(test_ds)} samples in it.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3Eq2V8sFOPs",
        "outputId": "c77cdfc0-da42-4cbb-c140-8ef1d0383f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel_values  :  torch.Size([3, 384, 384])\n",
            "labels  :  torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "encoding = train_ds[0]\n",
        "\n",
        "for k,v in encoding.items():\n",
        "    print(k, \" : \", v.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5S7jfD5Dg56",
        "outputId": "6e079b56-009c-4474-f49d-e98ced035420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B1260UL\n"
          ]
        }
      ],
      "source": [
        "labels = encoding['labels']\n",
        "labels[labels == -100] = processor.tokenizer.pad_token_id\n",
        "label_str = processor.decode(labels, skip_special_tokens=True)\n",
        "print(label_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config Model"
      ],
      "metadata": {
        "id": "z9EaVnYDcHLs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5tEtME7FeNp"
      },
      "outputs": [],
      "source": [
        "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
        "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "\n",
        "model.config.vocab_size = model.config.decoder.vocab_size\n",
        "\n",
        "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
        "model.config.max_length = 16\n",
        "model.config.early_stopping = True\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.length_penalty = 2.0\n",
        "model.config.num_beams = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WucFBHPFqgC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bba3ed2fdeb34ae39e7a0928872848e3",
            "e2652392c59f42998b00e6769c5b62d9",
            "9f9477bef2854fe6a9ab60d8f0a44019",
            "52e0a0a86efc458b89811c872b94d35a",
            "9750ac578cab45cfb7d4a463bd151da4",
            "0d8390c13db6470a81d7ac64fec2e4d5",
            "acacb0ab98364eac823b01dca0f1434c",
            "d607720186324c3c96c504571cbaaa4c",
            "863597a4ee074aefaf59af14a069747f",
            "13cf4d0fabef4835bb6c1bb86b8ac160",
            "34e8daea2a6e4573978fcc9819aa9745"
          ]
        },
        "outputId": "9e6ef5d7-3087-4618-9472-7ddcda235a21"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.60k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bba3ed2fdeb34ae39e7a0928872848e3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    label_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"cer\" : cer}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clear GPU RAM"
      ],
      "metadata": {
        "id": "3I82icv9F1dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCbUBE8hFmgd",
        "outputId": "5c7c3b90-d3bf-49f2-b4f6-fc7ba9d13fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.39.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.10/dist-packages (from numba) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba) (67.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from numba import cuda\n",
        "# device = cuda.get_current_device()\n",
        "# device.reset()"
      ],
      "metadata": {
        "id": "esLVRL0jFrBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Parameter Tuning"
      ],
      "metadata": {
        "id": "ffLvsYgKcQOX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEuSeyRSTHuE"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jNlRhfLGGPs"
      },
      "outputs": [],
      "source": [
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=MODEL_NAME,\n",
        "    num_train_epochs=NUM_OF_EPOCHS,\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsghlO03M1DR"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    args=args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    data_collator=default_data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Train"
      ],
      "metadata": {
        "id": "mii1zk1BcTpB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvQjTTieGMud",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "8b1a5eb3-4410-4585-8ba6-63066b5666c5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2560' max='2560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2560/2560 1:13:19, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Cer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.580932</td>\n",
              "      <td>0.097119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.846100</td>\n",
              "      <td>0.854526</td>\n",
              "      <td>0.104527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.846100</td>\n",
              "      <td>0.338219</td>\n",
              "      <td>0.057613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.265700</td>\n",
              "      <td>0.285628</td>\n",
              "      <td>0.041975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.094700</td>\n",
              "      <td>0.276158</td>\n",
              "      <td>0.044444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.094700</td>\n",
              "      <td>0.277554</td>\n",
              "      <td>0.037860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.041300</td>\n",
              "      <td>0.284300</td>\n",
              "      <td>0.035391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.012900</td>\n",
              "      <td>0.286221</td>\n",
              "      <td>0.037037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_results = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu7ArpGai6P2",
        "outputId": "faa97e75-3978-45a1-f385-c92d74073af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =          8.0\n",
            "  total_flos               = 6406957440GF\n",
            "  train_loss               =       0.2464\n",
            "  train_runtime            =   1:13:26.71\n",
            "  train_samples_per_second =        1.162\n",
            "  train_steps_per_second   =        0.581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/trocr-large-str_license_plates_ocr.zip /content/trocr-large-str_license_plates_ocr\n",
        "# change sample_data.zip to your desired download name Ex: nothing.zip\n",
        "# change sample_data to your desired download folder name Ex: ner_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX4IZL0U8idJ",
        "outputId": "c839bb5a-04a1-404f-d4a2-85f952c70691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/trocr-large-str_license_plates_ocr/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/train_results.json (deflated 37%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/training_args.bin (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/all_results.json (deflated 54%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/config.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/rng_state.pth (deflated 28%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/training_args.bin (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/config.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/trainer_state.json (deflated 73%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/preprocessor_config.json (deflated 48%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/optimizer.pt (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/generation_config.json (deflated 40%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1920/scheduler.pt (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/trainer_state.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/rng_state.pth (deflated 28%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/training_args.bin (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/config.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/trainer_state.json (deflated 68%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/preprocessor_config.json (deflated 48%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/optimizer.pt (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/generation_config.json (deflated 40%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1280/scheduler.pt (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/preprocessor_config.json (deflated 48%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/eval_results.json (deflated 41%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/rng_state.pth (deflated 28%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/training_args.bin (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/config.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/trainer_state.json (deflated 63%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/preprocessor_config.json (deflated 48%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/optimizer.pt (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/generation_config.json (deflated 40%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-960/scheduler.pt (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/runs/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/runs/Jul07_13-12-38_ccbf2518271d/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/runs/Jul07_13-12-38_ccbf2518271d/events.out.tfevents.1688735590.ccbf2518271d.886.0 (deflated 68%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/runs/Jul07_13-12-38_ccbf2518271d/events.out.tfevents.1688740895.ccbf2518271d.886.1 (deflated 27%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/rng_state.pth (deflated 28%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/training_args.bin (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/config.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/trainer_state.json (deflated 76%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/preprocessor_config.json (deflated 48%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/optimizer.pt (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/generation_config.json (deflated 40%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2560/scheduler.pt (deflated 50%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/generation_config.json (deflated 40%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/rng_state.pth (deflated 28%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/training_args.bin (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/config.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/trainer_state.json (deflated 74%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/preprocessor_config.json (deflated 48%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/optimizer.pt (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/generation_config.json (deflated 40%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-2240/scheduler.pt (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/rng_state.pth (deflated 28%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/training_args.bin (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/config.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/trainer_state.json (deflated 59%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/preprocessor_config.json (deflated 48%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/optimizer.pt (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/generation_config.json (deflated 40%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-640/scheduler.pt (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/rng_state.pth (deflated 28%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/training_args.bin (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/config.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/trainer_state.json (deflated 71%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/preprocessor_config.json (deflated 48%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/optimizer.pt (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/generation_config.json (deflated 40%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-1600/scheduler.pt (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/ (stored 0%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/rng_state.pth (deflated 28%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/training_args.bin (deflated 49%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/config.json (deflated 77%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/trainer_state.json (deflated 50%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/pytorch_model.bin (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/preprocessor_config.json (deflated 48%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/optimizer.pt (deflated 7%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/generation_config.json (deflated 40%)\n",
            "  adding: content/trocr-large-str_license_plates_ocr/checkpoint-320/scheduler.pt (deflated 49%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/trocr-large-str_license_plates_ocr.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "t8wsmR4ue-X-",
        "outputId": "c28eb06e-2a77-42ab-dd91-cb5726da0c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_281706c9-0fc9-4378-8562-519f51722241\", \"trocr-large-str_license_plates_ocr.zip\", 51727459272)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate()\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "Ot2nirMajGFM",
        "outputId": "23b8367b-b308-48b6-fca9-92f9148736ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80/80 02:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        8.0\n",
            "  eval_cer                =      0.037\n",
            "  eval_loss               =     0.2862\n",
            "  eval_runtime            = 0:02:25.50\n",
            "  eval_samples_per_second =        1.1\n",
            "  eval_steps_per_second   =       0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Trained Model"
      ],
      "metadata": {
        "id": "LNUabFercWha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and model\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"/content/trocr-large-str_license_plates_ocr/checkpoint-2560\")\n",
        "preprocessor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-str\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQWKH4xjqZ8m",
        "outputId": "cb138b75-fbd4-4c96-d60b-3781b79f3170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict and saving result"
      ],
      "metadata": {
        "id": "ufU-If-FcaE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv('/content/submission.csv')\n",
        "list_file = data_df['Name of File']\n",
        "base_path = '/content/PreprocessedTestImages/'\n",
        "image_path = ''\n",
        "\n",
        "for index, row in data_df.iterrows():\n",
        "\n",
        "    path = base_path + row['Name of File']\n",
        "    image_path = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "    # Preprocess the image using the processor\n",
        "    input_image = processor(images=image_path, return_tensors=\"pt\")\n",
        "\n",
        "    pixel_values = processor(images=image_path, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "    generated_ids = model.generate(pixel_values)\n",
        "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    print(f\"Filename : {row['Name of File']} \\n Plate : {generated_text}\\n\\n\")\n",
        "    new_value = generated_text\n",
        "\n",
        "    # Update the 'Vehicleregistrationplatebymodel' value in the DataFrame\n",
        "    data_df.loc[index, 'Vehicleregistrationplatebymodel'] = new_value\n",
        "\n",
        "# Save the updated DataFrame back to the CSV file\n",
        "data_df.to_csv('submission_updated.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmCQ1UIU6hoD",
        "outputId": "92af046f-6a34-4412-8c48-1be096fcd080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filename : DataTest1.png \n",
            " Plate : AD7034OE\n",
            "\n",
            "\n",
            "Filename : DataTest2.png \n",
            " Plate : A9388EX\n",
            "\n",
            "\n",
            "Filename : DataTest3.png \n",
            " Plate : B16TB\n",
            "\n",
            "\n",
            "Filename : DataTest4.png \n",
            " Plate : B1661TKZ\n",
            "\n",
            "\n",
            "Filename : DataTest5.png \n",
            " Plate : AD3772ABE\n",
            "\n",
            "\n",
            "Filename : DataTest6.png \n",
            " Plate : B1271HV\n",
            "\n",
            "\n",
            "Filename : DataTest7.png \n",
            " Plate : B1064TFR\n",
            "\n",
            "\n",
            "Filename : DataTest8.png \n",
            " Plate : B1395TJW\n",
            "\n",
            "\n",
            "Filename : DataTest9.png \n",
            " Plate : B1270RFD\n",
            "\n",
            "\n",
            "Filename : DataTest10.png \n",
            " Plate : B1736BYH\n",
            "\n",
            "\n",
            "Filename : DataTest11.png \n",
            " Plate : B1627BIE\n",
            "\n",
            "\n",
            "Filename : DataTest12.png \n",
            " Plate : B1678WZM\n",
            "\n",
            "\n",
            "Filename : DataTest13.png \n",
            " Plate : AD9313SS\n",
            "\n",
            "\n",
            "Filename : DataTest14.png \n",
            " Plate : B1036UL\n",
            "\n",
            "\n",
            "Filename : DataTest15.png \n",
            " Plate : B1801TZS\n",
            "\n",
            "\n",
            "Filename : DataTest16.png \n",
            " Plate : B1474TJS\n",
            "\n",
            "\n",
            "Filename : DataTest17.png \n",
            " Plate : B1939PU\n",
            "\n",
            "\n",
            "Filename : DataTest18.png \n",
            " Plate : B1260TZT\n",
            "\n",
            "\n",
            "Filename : DataTest19.png \n",
            " Plate : B1376TJO\n",
            "\n",
            "\n",
            "Filename : DataTest20.png \n",
            " Plate : B17QO\n",
            "\n",
            "\n",
            "Filename : DataTest21.png \n",
            " Plate : AB6328LZ\n",
            "\n",
            "\n",
            "Filename : DataTest22.png \n",
            " Plate : B1236PZM\n",
            "\n",
            "\n",
            "Filename : DataTest23.png \n",
            " Plate : AB8644PK\n",
            "\n",
            "\n",
            "Filename : DataTest24.png \n",
            " Plate : B1KT\n",
            "\n",
            "\n",
            "Filename : DataTest25.png \n",
            " Plate : AA7084OD\n",
            "\n",
            "\n",
            "Filename : DataTest26.png \n",
            " Plate : B1131EKG\n",
            "\n",
            "\n",
            "Filename : DataTest27.png \n",
            " Plate : B1037JN\n",
            "\n",
            "\n",
            "Filename : DataTest28.png \n",
            " Plate : B1036UL\n",
            "\n",
            "\n",
            "Filename : DataTest29.png \n",
            " Plate : AD6820QO\n",
            "\n",
            "\n",
            "Filename : DataTest30.png \n",
            " Plate : A9192ZM\n",
            "\n",
            "\n",
            "Filename : DataTest31.png \n",
            " Plate : B0120KXT\n",
            "\n",
            "\n",
            "Filename : DataTest32.png \n",
            " Plate : B1643TRO\n",
            "\n",
            "\n",
            "Filename : DataTest33.png \n",
            " Plate : B1390TJU\n",
            "\n",
            "\n",
            "Filename : DataTest34.png \n",
            " Plate : AB2681VD\n",
            "\n",
            "\n",
            "Filename : DataTest35.png \n",
            " Plate : B1860EFT\n",
            "\n",
            "\n",
            "Filename : DataTest36.png \n",
            " Plate : A8749FS\n",
            "\n",
            "\n",
            "Filename : DataTest37.png \n",
            " Plate : B1566FON\n",
            "\n",
            "\n",
            "Filename : DataTest38.png \n",
            " Plate : B1063SJQ\n",
            "\n",
            "\n",
            "Filename : DataTest39.png \n",
            " Plate : B1254TFX\n",
            "\n",
            "\n",
            "Filename : DataTest40.png \n",
            " Plate : B1038JCY\n",
            "\n",
            "\n",
            "Filename : DataTest41.png \n",
            " Plate : AB4923UH\n",
            "\n",
            "\n",
            "Filename : DataTest42.png \n",
            " Plate : B1509UN\n",
            "\n",
            "\n",
            "Filename : DataTest43.png \n",
            " Plate : B1937TLP\n",
            "\n",
            "\n",
            "Filename : DataTest44.png \n",
            " Plate : B1202UL\n",
            "\n",
            "\n",
            "Filename : DataTest45.png \n",
            " Plate : B1026TMZ\n",
            "\n",
            "\n",
            "Filename : DataTest46.png \n",
            " Plate : B1724PYW\n",
            "\n",
            "\n",
            "Filename : DataTest47.png \n",
            " Plate : B1102SIV\n",
            "\n",
            "\n",
            "Filename : DataTest48.png \n",
            " Plate : AD7034OE\n",
            "\n",
            "\n",
            "Filename : DataTest49.png \n",
            " Plate : AB4152CX\n",
            "\n",
            "\n",
            "Filename : DataTest50.png \n",
            " Plate : B1895EJB\n",
            "\n",
            "\n",
            "Filename : DataTest51.png \n",
            " Plate : B1786UJT\n",
            "\n",
            "\n",
            "Filename : DataTest52.png \n",
            " Plate : B1549RFS\n",
            "\n",
            "\n",
            "Filename : DataTest53.png \n",
            " Plate : B1869EOF\n",
            "\n",
            "\n",
            "Filename : DataTest54.png \n",
            " Plate : B1713VX\n",
            "\n",
            "\n",
            "Filename : DataTest55.png \n",
            " Plate : B1063SPW\n",
            "\n",
            "\n",
            "Filename : DataTest56.png \n",
            " Plate : B1661TKZ\n",
            "\n",
            "\n",
            "Filename : DataTest57.png \n",
            " Plate : A8014VA\n",
            "\n",
            "\n",
            "Filename : DataTest58.png \n",
            " Plate : B1873YU\n",
            "\n",
            "\n",
            "Filename : DataTest59.png \n",
            " Plate : BJO24QO\n",
            "\n",
            "\n",
            "Filename : DataTest60.png \n",
            " Plate : B1422BK\n",
            "\n",
            "\n",
            "Filename : DataTest61.png \n",
            " Plate : AB5278XA\n",
            "\n",
            "\n",
            "Filename : DataTest62.png \n",
            " Plate : AD418U\n",
            "\n",
            "\n",
            "Filename : DataTest63.png \n",
            " Plate : B1157Y\n",
            "\n",
            "\n",
            "Filename : DataTest64.png \n",
            " Plate : B1233RFD\n",
            "\n",
            "\n",
            "Filename : DataTest65.png \n",
            " Plate : B1031NI\n",
            "\n",
            "\n",
            "Filename : DataTest66.png \n",
            " Plate : AD99JR\n",
            "\n",
            "\n",
            "Filename : DataTest67.png \n",
            " Plate : B1683SEY\n",
            "\n",
            "\n",
            "Filename : DataTest68.png \n",
            " Plate : AA7014QF\n",
            "\n",
            "\n",
            "Filename : DataTest69.png \n",
            " Plate : B1241SSW\n",
            "\n",
            "\n",
            "Filename : DataTest70.png \n",
            " Plate : B1632TJJ\n",
            "\n",
            "\n",
            "Filename : DataTest71.png \n",
            " Plate : B1907ELR\n",
            "\n",
            "\n",
            "Filename : DataTest72.png \n",
            " Plate : B1815TJQ\n",
            "\n",
            "\n",
            "Filename : DataTest73.png \n",
            " Plate : B1734UJN\n",
            "\n",
            "\n",
            "Filename : DataTest74.png \n",
            " Plate : B1743EYF\n",
            "\n",
            "\n",
            "Filename : DataTest75.png \n",
            " Plate : B1075QO\n",
            "\n",
            "\n",
            "Filename : DataTest76.png \n",
            " Plate : AB2933IN\n",
            "\n",
            "\n",
            "Filename : DataTest77.png \n",
            " Plate : B1523TJT\n",
            "\n",
            "\n",
            "Filename : DataTest78.png \n",
            " Plate : B1157SSL\n",
            "\n",
            "\n",
            "Filename : DataTest79.png \n",
            " Plate : B1713VX\n",
            "\n",
            "\n",
            "Filename : DataTest80.png \n",
            " Plate : B1361TJS\n",
            "\n",
            "\n",
            "Filename : DataTest81.png \n",
            " Plate : A9388EX\n",
            "\n",
            "\n",
            "Filename : DataTest82.png \n",
            " Plate : B1532NKY\n",
            "\n",
            "\n",
            "Filename : DataTest83.png \n",
            " Plate : B1808UYU\n",
            "\n",
            "\n",
            "Filename : DataTest84.png \n",
            " Plate : B1411TVE\n",
            "\n",
            "\n",
            "Filename : DataTest85.png \n",
            " Plate : AB3787KE\n",
            "\n",
            "\n",
            "Filename : DataTest86.png \n",
            " Plate : B1339RFD\n",
            "\n",
            "\n",
            "Filename : DataTest87.png \n",
            " Plate : B1903RFD\n",
            "\n",
            "\n",
            "Filename : DataTest88.png \n",
            " Plate : AB2958QH\n",
            "\n",
            "\n",
            "Filename : DataTest89.png \n",
            " Plate : AD418U\n",
            "\n",
            "\n",
            "Filename : DataTest90.png \n",
            " Plate : B1885TLP\n",
            "\n",
            "\n",
            "Filename : DataTest91.png \n",
            " Plate : B1634SSN\n",
            "\n",
            "\n",
            "Filename : DataTest92.png \n",
            " Plate : AB3511OH\n",
            "\n",
            "\n",
            "Filename : DataTest93.png \n",
            " Plate : B1726UUA\n",
            "\n",
            "\n",
            "Filename : DataTest94.png \n",
            " Plate : B1820TJV\n",
            "\n",
            "\n",
            "Filename : DataTest95.png \n",
            " Plate : B1619URB\n",
            "\n",
            "\n",
            "Filename : DataTest96.png \n",
            " Plate : B1265UL\n",
            "\n",
            "\n",
            "Filename : DataTest97.png \n",
            " Plate : AB8644PK\n",
            "\n",
            "\n",
            "Filename : DataTest98.png \n",
            " Plate : AG9718EG\n",
            "\n",
            "\n",
            "Filename : DataTest99.png \n",
            " Plate : B1509UN\n",
            "\n",
            "\n",
            "Filename : DataTest100.png \n",
            " Plate : B1408RX\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "collapsed_sections": [
        "UMpQdgoUBCq4",
        "I23SU1sk_Hlt",
        "Vf56eeNDA1ij",
        "GzPpllNgZJKd",
        "rwYpBViUA6nU",
        "3I82icv9F1dN"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bba3ed2fdeb34ae39e7a0928872848e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2652392c59f42998b00e6769c5b62d9",
              "IPY_MODEL_9f9477bef2854fe6a9ab60d8f0a44019",
              "IPY_MODEL_52e0a0a86efc458b89811c872b94d35a"
            ],
            "layout": "IPY_MODEL_9750ac578cab45cfb7d4a463bd151da4"
          }
        },
        "e2652392c59f42998b00e6769c5b62d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d8390c13db6470a81d7ac64fec2e4d5",
            "placeholder": "​",
            "style": "IPY_MODEL_acacb0ab98364eac823b01dca0f1434c",
            "value": "Downloading builder script: 100%"
          }
        },
        "9f9477bef2854fe6a9ab60d8f0a44019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d607720186324c3c96c504571cbaaa4c",
            "max": 5599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_863597a4ee074aefaf59af14a069747f",
            "value": 5599
          }
        },
        "52e0a0a86efc458b89811c872b94d35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13cf4d0fabef4835bb6c1bb86b8ac160",
            "placeholder": "​",
            "style": "IPY_MODEL_34e8daea2a6e4573978fcc9819aa9745",
            "value": " 5.60k/5.60k [00:00&lt;00:00, 213kB/s]"
          }
        },
        "9750ac578cab45cfb7d4a463bd151da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8390c13db6470a81d7ac64fec2e4d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acacb0ab98364eac823b01dca0f1434c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d607720186324c3c96c504571cbaaa4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "863597a4ee074aefaf59af14a069747f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13cf4d0fabef4835bb6c1bb86b8ac160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e8daea2a6e4573978fcc9819aa9745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}